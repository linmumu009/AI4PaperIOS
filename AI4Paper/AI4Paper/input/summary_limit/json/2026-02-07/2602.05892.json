{
  "institution": "南大",
  "short_title": "构建首个代码上下文检索基准",
  "📖标题": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
  "🌐来源": "arxiv",
  "paper_id": "2602.05892",
  "🛎️文章简介": {
    "🔸研究问题": "LLM编码代理在解决软件工程问题时，如何有效检索和利用关键代码上下文？",
    "🔸主要贡献": "提出了CONTEXTBENCH——首个面向过程、含人工标注黄金上下文的大规模多语言代码上下文检索评测基准。"
  },
  "📝重点思路": [
    "🔸基于四大现有基准（SWE-bench等）进行规则+嵌入双重去重，筛选出3100个唯一任务；",
    "🔸依据代理可解性、编辑范围与分散度三项指标筛选1136个高难度任务；",
    "🔸由六位作者联合资深开发者开展四个月人机协同标注，通过迭代追踪依赖链生成紧凑黄金上下文；",
    "🔸采用Tree-Sitter解析统一坐标系，在文件/块/行三级粒度上对齐黄金上下文与代理检索结果；",
    "🔸设计覆盖召回率、精确率、F1、效率、冗余度及使用衰减的全流程动态评估框架。"
  ],
  "🔎分析总结": [
    "🔸复杂代理架构（如Prometheus、OpenHands）并未显著提升上下文检索性能，印证“苦涩教训”；",
    "🔸所有前沿LLM均倾向高召回低精度策略，引入大量噪声，块级F1普遍低于0.45；",
    "🔸上下文检索存在明显“用而未取”现象:平均近20%已探索黄金上下文未被最终补丁采纳；",
    "🔸均衡策略更优:Claude Sonnet 4.5以中等步数+中等粒度实现最高行级F1与Pass@1；",
    "🔸黄金上下文跨等价补丁的Jaccard相似率达0.95，验证其鲁棒性与可靠性。"
  ],
  "💡个人观点": "该工作突破性地将黑盒式端到端评测转向可解释的过程评估，其核心创新在于:①首次系统定义并人工构造覆盖8种语言、超52万行代码的黄金上下文；②提出结构化、可复现、多粒度的上下文检索动态评测范式；③揭示“检索≠使用”这一关键瓶颈，为改进代理记忆机制与证据整合能力提供明确优化方向。"
}