{
  "institution": "北大",
  "short_title": "构建归纳式智能体评测新基准",
  "📖标题": "OdysseyArena: Benchmarking Large Language Models For Long-Horizon, Active and Inductive Interactions",
  "🌐来源": "arxiv",
  "paper_id": "2602.05843",
  "🛎️文章简介": {
    "🔸研究问题": "如何评估大语言模型在长周期、主动探索和归纳推理任务中的真实世界建模能力？",
    "🔸主要贡献": "提出ODYSSEYARENA基准，首次系统化评测LLM通过交互自主归纳环境隐含规则的能力，并揭示当前模型存在根本性归纳瓶颈。"
  },
  "📝重点思路": [
    "🔸解构环境动态为四类原语：离散符号规则、连续随机动力学、周期性时间模式、关系图结构。",
    "🔸构建四个轻量交互环境（Turn On Lights、AI Trading、Energy Dispatch、Repo System），各隐藏一类转移函数τ供代理推断。",
    "🔸发布ODYSSEYARENA-LITE（120任务）评测归纳效率，及ODYSSEYARENA-CHALLENGE（周期>1000步）测试长期策略稳定性。",
    "🔸所有任务采用确定性轨迹，难度由灯数、因子维度、周期长度等参数调控，保障复现性与公平比较。"
  ],
  "🔎分析总结": [
    "🔸即使最强商业模型（Gemini 3 Pro Preview）在LITE上平均成功率仅44.17%，远低于人类100%，证明归纳能力是核心短板而非规模问题。",
    "🔸当提供显式规则时，前沿模型成功率跃升至近100%，证实其强演绎能力与弱归纳能力的显著不对称性。",
    "🔸大量模型出现“动作循环”现象（重复无效操作），且循环率越高成功率越低，表明其无法将试错转化为知识更新。",
    "🔸性能在初始探索后迅速饱和，延长交互步数几乎不提升成功率，说明缺乏内在世界模型导致归纳停滞，而非数据不足。"
  ],
  "💡个人观点": "该论文的创新点在于跳脱传统指令遵循范式，将“自主发现世界规律”确立为智能体的核心能力，并通过形式化四类结构原语+可扩展轻量环境+双粒度评测协议，首次构建了面向归纳智能的科学评测框架，为突破当前LLM“知其然不知其所以然”的局限指明了关键路径。"
}